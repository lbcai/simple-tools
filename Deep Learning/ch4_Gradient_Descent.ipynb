{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "exact-input",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30250000000000005\n"
     ]
    }
   ],
   "source": [
    "# Grokking Deep Learning by Andrew W. Trask\n",
    "# Ch 4: Gradient Descent\n",
    "\n",
    "# Mean Squared Error: one simple way to calculate error of prediction.\n",
    "\n",
    "knob_weight = 0.5\n",
    "input = 0.5\n",
    "\n",
    "# Real measured result.\n",
    "goal_pred = 0.8\n",
    "\n",
    "pred = input * knob_weight\n",
    "\n",
    "# Squared to force positive error. Negative error does not make sense since we consider all error positive.\n",
    "# Also, small <1 errors are reduced in importance and big >1 errors are amplified in importance, which is okay\n",
    "# since this is realistic (if error is 10, adjusted = 100; if 0.01, adjusted = 0.0001). Ideally, we want error to be 0.\n",
    "error = (pred - goal_pred) ** 2\n",
    "\n",
    "print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "regulation-blank",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = 0.5\n",
    "input = 0.5\n",
    "goal_prediction = 0.8\n",
    "\n",
    "# how much to move the weight every time it corrects itself\n",
    "step_amount = 0.001\n",
    "\n",
    "for iteration in range(1101):\n",
    "    prediction = input * weight\n",
    "    error = (prediction - goal_prediction) ** 2\n",
    "    \n",
    "    # commented out the print statement because it produces huge block of text\n",
    "    # print(\"Error: \" + str(error) + \"  Prediction: \" + str(prediction))\n",
    "    \n",
    "    up_prediction = input * (weight + step_amount)\n",
    "    up_error = (goal_prediction - up_prediction) ** 2\n",
    "    \n",
    "    down_prediction = input * (weight - step_amount)\n",
    "    down_error = (goal_prediction - down_prediction) ** 2\n",
    "    \n",
    "    if (down_error < up_error):\n",
    "        weight = weight - step_amount\n",
    "    elif (down_error > up_error):\n",
    "        weight = weight + step_amount\n",
    "\n",
    "# This is hot and cold learning. It's inefficient and the fixed step amount is a bummer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "posted-refund",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0.30250000000000005  Prediction: 0.25\n",
      "Error: 0.17015625000000004  Prediction: 0.3875\n",
      "Error: 0.095712890625  Prediction: 0.49062500000000003\n",
      "Error: 0.05383850097656251  Prediction: 0.56796875\n",
      "Error: 0.03028415679931642  Prediction: 0.6259765625\n",
      "Error: 0.0170348381996155  Prediction: 0.669482421875\n",
      "Error: 0.00958209648728372  Prediction: 0.70211181640625\n",
      "Error: 0.005389929274097089  Prediction: 0.7265838623046875\n",
      "Error: 0.0030318352166796153  Prediction: 0.7449378967285156\n",
      "Error: 0.0017054073093822882  Prediction: 0.7587034225463867\n",
      "Error: 0.0009592916115275371  Prediction: 0.76902756690979\n",
      "Error: 0.0005396015314842384  Prediction: 0.7767706751823426\n",
      "Error: 0.000303525861459885  Prediction: 0.7825780063867569\n",
      "Error: 0.00017073329707118678  Prediction: 0.7869335047900676\n",
      "Error: 9.603747960254256e-05  Prediction: 0.7902001285925507\n",
      "Error: 5.402108227642978e-05  Prediction: 0.7926500964444131\n",
      "Error: 3.038685878049206e-05  Prediction: 0.7944875723333098\n",
      "Error: 1.7092608064027242e-05  Prediction: 0.7958656792499823\n",
      "Error: 9.614592036015323e-06  Prediction: 0.7968992594374867\n",
      "Error: 5.408208020258491e-06  Prediction: 0.7976744445781151\n"
     ]
    }
   ],
   "source": [
    "# In comparison, here is GRADIENT DESCENT. It calculates the direction and the amount of the step we should apply\n",
    "# to the weight in one calculation.\n",
    "\n",
    "weight = 0.5\n",
    "goal_pred = 0.8\n",
    "input = 0.5\n",
    "\n",
    "for iteration in range(20):\n",
    "    pred = input * weight\n",
    "    error = (pred - goal_pred) ** 2\n",
    "    \n",
    "    # Gradient descent!\n",
    "    # Multiply pure error (pred - goal_pred) by input to address edge cases by adding stopping (0 input), \n",
    "    # negative reversal (negative input), and scaling (large input should move the weight more so we don't take forever \n",
    "    # with tiny steps)\n",
    "    # pure error = raw amount that you were off (big = big error, positive = too high and not too low, etc.)\n",
    "    \n",
    "    # There are 3 edge cases where the pure error is not enough to give a good amount you should modify the weight (knob).\n",
    "    # 1. When the input is 0 (stopping): there is nothing to learn when input is 0 because all weight values give the same\n",
    "    #    error value. When input is 0, we should ignore it or else we can make bad conclusions. We multiply by input (which is\n",
    "    #    0 in this case) and this prevents learning because the direction_and_amount will be 0 so there is no change.\n",
    "    # 2. When the input is negative (negative reversal): if you expect negative input, you can't learn properly from it because\n",
    "    #    when you move the weight up, you are really making it a smaller negative number (-1 -> -10), which causes the model\n",
    "    #    to think that it is more wrong instead of more right. If input is negative, since we multiply the pure error by input,\n",
    "    #    it will flip the sign to the right direction.\n",
    "    # 3. When the input is large (scaling): large input means the weight update should also be large. By multiplying the pure \n",
    "    #    error by input, we can make sure this is true. We will see examples later where this gets out of control and we will\n",
    "    #    use alpha to fix that. Alpha is a value that prevents learning too quickly or else the network can overshoot by editing\n",
    "    #    weights too aggressively.\n",
    "    direction_and_amount = (pred - goal_pred) * input\n",
    "    \n",
    "    weight = weight - direction_and_amount\n",
    "    \n",
    "    # This produces a much smaller block of text than the hot/cold method above.\n",
    "    print(\"Error: \" + str(error) + \"  Prediction: \" + str(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stopped-difficulty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pred = input * weight\n",
    "# error = (pred - goal_pred) ** 2\n",
    "\n",
    "# Error and weight have an exact relationship defined:\n",
    "# error = ((input * weight) - goal_pred) ** 2\n",
    "\n",
    "# The above equation forms a parabola. The lowest point on this parabola is the place where there is 0 error and the graph\n",
    "# touches the x-axis, y is 0. \n",
    "# Any point on the parabola represents the current weight and the current error. Any point has a slope tangential to the graph \n",
    "# of the parabola. This slope always points towards the lowest point on the graph, meaning we can use the slope to find out the \n",
    "# direction and magnitude we should apply to weight to reach an error of 0.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(-10, 11, 1)\n",
    "y = x ** 2\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.xlabel(\"Weight\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlim(-10, 10)\n",
    "plt.ylim(-10, 100)\n",
    "\n",
    "x_error = np.array([0])\n",
    "y_error = np.array([0])\n",
    "x_error2 = np.array([-6])\n",
    "y_error2 = np.array([36])\n",
    "plt.scatter(x_error, y_error, s = 300, color = \"black\", facecolors = \"none\", linestyle = \"dashed\")\n",
    "plt.scatter(x_error2, y_error2, s = 150)\n",
    "\n",
    "plt.axhline(0, color = \"black\", linewidth = 1)\n",
    "# equation for the slope at the point happens to be y = -12x - 36\n",
    "plt.annotate(\"\", xy = (-4, 12), xytext = (-8, 60), arrowprops = dict(arrowstyle = \"->\"))\n",
    "plt.annotate(\"no error\", xy = (0, 0), xytext = (-1.6, 10))\n",
    "plt.plot(x, y)\n",
    "plt.show()\n",
    "\n",
    "# Machine learning research is about applying new things to the pred = input * weight equation to make better models. We cannot \n",
    "# change input because that's what we observed in the real world (so we would be interpreting results according to our whims)\n",
    "# but we can change weight to change how we predict and reduce error.\n",
    "\n",
    "# The graph represents what happens if you have a fixed input and goal_pred but plot every weight and each of their errors. \n",
    "# There will be a weight that gives a result with no error. This is the weight we want for this input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "saving-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The derivative is just the relationship between two variables. So derivative of y = 2x is just 2, and this means if y is moved\n",
    "# in a direction, x will move in the same direction twice as much. If the derivative is negative, then when you change one \n",
    "# variable, the other moves in the opposite direction. \n",
    "\n",
    "# The derivative is also the slope of a line at a point on a curve (see graph above). The derivative tells us how far we are\n",
    "# from the weight value that will give us no error. It tells us the relationship between weight and error.\n",
    "\n",
    "# The slope has an inverse relationship with the amount we should correct our weight. So a negative slope means we are too low\n",
    "# and should aim higher, adding a positive value to our weight, as in the graph above.\n",
    "\n",
    "# The derivative is just raw error * input. It is just direction_and_amount above. \n",
    "# delta = pred - goal_pred\n",
    "# weight_delta = delta * input <- the derivative, the slope\n",
    "# weight = weight - weight_delta <- minus because of the inverse relationship. Update the weight, learn.\n",
    "\n",
    "# Divergence\n",
    "# Now let's talk about alpha. If input is large, the update to the weight will be large. This causes problems when the error is\n",
    "# small. It will make us overshoot the prediction. Since it was a large input, we overshot the prediction by a lot. Since we\n",
    "# are so far off now, we have a very high error and this will cause us to overshoot again in the opposite direction. So we kind\n",
    "# of dropped a ball into a bowl and it's just accelerating somehow over and over. That is divergence.\n",
    "\n",
    "# weight = weight - (input * (pred - goal_pred))\n",
    "\n",
    "# Basically, the derivative is really big. Small changes in weight mean big changes in error. We multiply the derivative by\n",
    "# alpha to make it smaller and allow us more flexibility and improve our correction ability.\n",
    "\n",
    "# If learning is too slow, increase alpha. If divergence is observed (increasing error), then you decrease alpha. Alpha is \n",
    "# determined with trial and error.\n",
    "\n",
    "# weight = weight - (derivative * alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ambient-perception",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  6272.64  Weight:  -1.1680000000000001  Pred:  80\n",
      "Error:  2258.1504000000004  Weight:  0.7328000000000001  Pred:  -46.720000000000006\n",
      "Error:  812.9341440000002  Weight:  -0.40768000000000004  Pred:  29.312000000000005\n",
      "Error:  292.6562918400001  Weight:  0.2766080000000001  Pred:  -16.3072\n",
      "Error:  105.35626506240003  Weight:  -0.13396479999999994  Pred:  11.064320000000002\n",
      "Error:  37.92825542246398  Weight:  0.11237887999999999  Pred:  -5.358591999999998\n",
      "Error:  13.654171952087035  Weight:  -0.03542732799999998  Pred:  4.495155199999999\n",
      "Error:  4.915501902751332  Weight:  0.053256396799999994  Pred:  -1.4170931199999992\n",
      "Error:  1.7695806849904796  Weight:  4.616192000000269e-05  Pred:  2.1302558719999998\n",
      "Error:  0.6370490465965728  Weight:  0.031972302848  Pred:  0.0018464768000001075\n",
      "Error:  0.22933765677476622  Weight:  0.0128166182912  Pred:  1.27889211392\n",
      "Error:  0.0825615564389159  Weight:  0.024310029025280004  Pred:  0.512664731648\n",
      "Error:  0.02972216031800977  Weight:  0.017413982584831997  Pred:  0.9724011610112002\n",
      "Error:  0.01069997771448353  Weight:  0.021551610449100804  Pred:  0.6965593033932799\n",
      "Error:  0.003851991977214079  Weight:  0.019069033730539517  Pred:  0.8620644179640322\n",
      "Error:  0.0013867171117970735  Weight:  0.020558579761676292  Pred:  0.7627613492215807\n",
      "Error:  0.0004992181602469494  Weight:  0.019664852142994224  Pred:  0.8223431904670517\n",
      "Error:  0.0001797185376889036  Weight:  0.020201088714203466  Pred:  0.786594085719769\n",
      "Error:  6.469867356800458e-05  Weight:  0.019879346771477922  Pred:  0.8080435485681386\n",
      "Error:  2.3291522484481005e-05  Weight:  0.020072391937113247  Pred:  0.795173870859117\n"
     ]
    }
   ],
   "source": [
    "# Try to code gradient descent neural network on your own.\n",
    "alpha = 0.001\n",
    "weight = 2\n",
    "goal_pred = 0.8\n",
    "input = 40\n",
    "\n",
    "for iteration in range(20):\n",
    "    pred = input * weight\n",
    "    error = (pred - goal_pred) ** 2\n",
    "    derivative = (pred - goal_pred) * input\n",
    "    \n",
    "    # Update the weight each iteration = learning.\n",
    "    weight = weight - (derivative * alpha)\n",
    "    \n",
    "    print(\"Error: \", error, \" Weight: \", weight, \" Pred: \", pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
