{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proprietary-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-input and multi-input gradient descent are almost the same. The only difference is that with multi-input, you have\n",
    "# more than one input and each input must be multiplied by delta (pred - true) individually to affect the output the way we\n",
    "# want. weight_delta (input * (pred - true)) aka the derivative is then subtracted from the weight for each input. alpha is also\n",
    "# applied to each weight_delta when updating each weight.\n",
    "\n",
    "# There are multiple inputs and multiple weights (because each input needs a weight), but there is still only one error value\n",
    "# ((pred - true) ** 2) because there is one prediction.\n",
    "\n",
    "# Remember that delta is raw error. It is a measure of how different you want the prediction to be. weight_delta is the actual\n",
    "# estimate for how much we should adjust an input's weight to get the result we want (the derivative-based estimate).\n",
    "\n",
    "# The parabola that represents error over weight is narrower with larger inputs and wider with smaller ones. This is because\n",
    "# larger inputs = higher derivative/bigger slope values to get to the error = 0 point.\n",
    "\n",
    "# If one input is larger than the others, learning tends to favor making changes to the weight for this input. That's because\n",
    "# a large input has the ability to make large changes to the output more easily. You may also have issues with divergence with\n",
    "# this output while the other outputs are fine. You might have to use lower alpha values than would otherwise be desirable.\n",
    "# There is a subfield called normalization that deals with this problem and encourages learning across all weights.\n",
    "\n",
    "# Freezing a weight\n",
    "# You can learn by editing the weights of the other two smaller inputs and freezing the weight of the large input. The large\n",
    "# input will still get its error down near 0 because, once again, there is only one prediction and one error value.\n",
    "# This could be bad because the network could learn how to predict without the large input. Assuming this large input is\n",
    "# actually important to the prediction process, the network is missing data when making predictions.\n",
    "\n",
    "# You can also have 1 input and multiple outputs. This works the same as above except there is one input and multiple delta\n",
    "# values. weight_delta = input * (pred - true) for each of these. Each of the new weight_deltas is again multiplied by the alpha\n",
    "# and each weight is updated.\n",
    "\n",
    "# For networks with multiple inputs and multiple outputs, first calculate the error and delta for each output. Then, treat\n",
    "# each input like a network with multiple outputs and multiply all the deltas for each output by that input to get weight_delta.\n",
    "# Next, multiply all weight_deltas by the appropriate alpha value (there should be one for each input) and update the weight of\n",
    "# that input for each output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "magnetic-broadcasting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:  1\n",
      "Error:  [0.20702500000000007, 0.0003999999999999963, 0.7482250000000001]\n",
      "Weights:  [[0.061325, 0.061325, -0.338675], [0.10013000000000001, 0.20013, 0.00012999999999999942], [-0.01038, 1.28962, 0.08962]]\n",
      "Round:  2\n",
      "Error:  [0.03662247689999995, 0.012434034064000036, 1.1016433664640002]\n",
      "Weights:  [[0.04314485000000001, 0.04314485000000001, -0.35685515], [0.09923793600000001, 0.199237936, -0.000762064000000002], [-0.024024696, 1.275975304, 0.07597530400000001]]\n",
      "Round:  3\n",
      "Error:  [0.08021488254618248, 1.3029420795787903, 0.5197305555884246]\n",
      "Weights:  [[0.015105840319999998, 0.015105840319999998, -0.38489415968], [0.0901062169344, 0.1901062169344, -0.009893783065600004], [-0.027629313024000002, 1.2723706869759999, 0.072370686976]]\n",
      "Round:  4\n",
      "Error:  [0.1124571680947903, 0.0007751900729065042, 0.5911156960471249]\n",
      "Weights:  [[0.04528701096608001, 0.04528701096608001, -0.35471298903392], [0.09035679705313536, 0.19035679705313535, -0.009643202946864646], [-0.035317717904384004, 1.2646822820956158, 0.06468228209561601]]\n"
     ]
    }
   ],
   "source": [
    "# Example of a multi-input multi-output gradient descent neural network:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "          # toes %win # fans   predictions:\n",
    "weights = [[0.1, 0.1, -0.3], # players hurt?\n",
    "          [0.1, 0.2, 0.0],   # did the team win?\n",
    "          [0.0, 1.3, 0.1]]   # players sad?\n",
    "\n",
    "# multiply two vectors together and then add up all the parts\n",
    "def w_sum(a, b):\n",
    "    assert (len(a) == len(b))\n",
    "    output = 0\n",
    "    for i in range(len(a)):\n",
    "        output += (a[i] * b[i])\n",
    "    return output\n",
    "\n",
    "# multiply a vector in the matrix by one outside vector, then sum the parts of the resulting vector to get one value per\n",
    "# vector in the matrix\n",
    "def vector_matrix_multiplication (vect, matrix):\n",
    "    assert(len(vect) == len(matrix))\n",
    "    output = [0, 0, 0]\n",
    "    for i in range(len(vect)):\n",
    "        output[i] = w_sum(vect, matrix[i])\n",
    "    return output\n",
    "\n",
    "# multiply the inputs by the weights to get the prediction. the weights are a set of weights for each input, each set\n",
    "# has one value corresponding to each output (matrix). the inputs are one value per input (vector).\n",
    "# we get one prediction for each output: hurt, win, sad\n",
    "def neural_network(input, weights):\n",
    "    pred = vector_matrix_multiplication(input, weights)\n",
    "    return pred\n",
    "\n",
    "# multiply input by delta to get weight_delta. multiplies each input by 3 deltas because one input goes into 3 outputs.\n",
    "# and there are 3 inputs. the inputs each contribute to each output.\n",
    "def outer_prod(vec_a, vec_b):\n",
    "    out = np.zeros([len(vec_a), len(vec_b)])\n",
    "    for i in range(len(vec_a)):\n",
    "        for j in range(len(vec_b)):\n",
    "            out[i][j] = vec_a[i] * vec_b[i]\n",
    "    return out\n",
    "\n",
    "#inputs\n",
    "toes = [8.5, 9.5, 9.9, 9.0] # current average number of toes per player\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9] # current games won (%)\n",
    "nfans = [1.2, 1.3, 0.5, 1.0] # number of fans (millions)\n",
    "\n",
    "#true value\n",
    "hurt = [0.1, 0.0, 0.0, 0.1]\n",
    "win = [1, 1, 0, 1]\n",
    "sad = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "for n in range(0, 4):\n",
    "\n",
    "    input = [toes[n], wlrec[n], nfans[n]]\n",
    "    true = [hurt[n], win[n], sad[n]]\n",
    "\n",
    "    pred = neural_network(input, weights)\n",
    "\n",
    "    error = [0, 0, 0]\n",
    "    delta = [0, 0, 0]\n",
    "\n",
    "    # since we are only using 0th of each input and each true value, we are only getting learning for one set of inputs right now\n",
    "    for i in range(len(true)):\n",
    "        error[i] = (pred[i] - true[i]) ** 2\n",
    "        delta[i] = pred[i] - true[i]\n",
    "\n",
    "    weight_deltas = outer_prod(input, delta)\n",
    "\n",
    "    for i in range(len(weights)):\n",
    "        for j in range(len(weights[0])):\n",
    "            weights[i][j] -= alpha * weight_deltas[i][j]\n",
    "\n",
    "    # show the adjusted weight after the current round of learning\n",
    "    print(\"Round: \", n + 1)\n",
    "    print(\"Error: \", error)\n",
    "    print(\"Weights: \", weights)\n",
    "\n",
    "# Some divergence may be happening, but we only have 4 data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-afternoon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
