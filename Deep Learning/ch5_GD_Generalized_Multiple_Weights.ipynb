{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proprietary-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single-input and multi-input gradient descent are almost the same. The only difference is that with multi-input, you have\n",
    "# more than one input and each input must be multiplied by delta (pred - true) individually to affect the output the way we\n",
    "# want. weight_delta (input * (pred - true)) aka the derivative is then subtracted from the weight for each input. alpha is also\n",
    "# applied to each weight_delta when updating each weight.\n",
    "\n",
    "# There are multiple inputs and multiple weights (because each input needs a weight), but there is still only one error value\n",
    "# ((pred - true) ** 2) because there is one prediction.\n",
    "\n",
    "# Remember that delta is raw error. It is a measure of how different you want the prediction to be. weight_delta is the actual\n",
    "# estimate for how much we should adjust an input's weight to get the result we want (the derivative-based estimate).\n",
    "\n",
    "# The parabola that represents error over weight is narrower with larger inputs and wider with smaller ones. This is because\n",
    "# larger inputs = higher derivative/bigger slope values to get to the error = 0 point.\n",
    "\n",
    "# If one input is larger than the others, learning tends to favor making changes to the weight for this input. That's because\n",
    "# a large input has the ability to make large changes to the output more easily. You may also have issues with divergence with\n",
    "# this output while the other outputs are fine. You might have to use lower alpha values than would otherwise be desirable.\n",
    "# There is a subfield called normalization that deals with this problem and encourages learning across all weights.\n",
    "\n",
    "# Freezing a weight\n",
    "# You can learn by editing the weights of the other two smaller inputs and freezing the weight of the large input. The large\n",
    "# input will still get its error down near 0 because, once again, there is only one prediction and one error value.\n",
    "# This could be bad because the network could learn how to predict without the large input. Assuming this large input is\n",
    "# actually important to the prediction process, the network is missing data when making predictions.\n",
    "\n",
    "# You can also have 1 input and multiple outputs. This works the same as above except there is one input and multiple delta\n",
    "# values. weight_delta = input * (pred - true) for each of these. Each of the new weight_deltas is again multiplied by the alpha\n",
    "# and each weight is updated.\n",
    "\n",
    "# For networks with multiple inputs and multiple outputs, first calculate the error and delta for each output. Then, treat\n",
    "# each input like a network with multiple outputs and multiply all the deltas for each output by that input to get weight_delta.\n",
    "# Next, multiply all weight_deltas by the appropriate alpha value (there should be one for each input) and update the weight of\n",
    "# that input for each output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "magnetic-broadcasting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round:  1\n",
      "Pred:  [0.555, 0.9800000000000001, 0.9650000000000001]\n",
      "Error:  [0.20702500000000007, 0.0003999999999999963, 0.7482250000000001]\n",
      "Round:  2\n",
      "Pred:  [0.19136999999999987, 1.1115080000000002, 1.049592]\n",
      "Error:  [0.03662247689999995, 0.012434034064000036, 1.1016433664640002]\n",
      "Round:  3\n",
      "Pred:  [0.28322232000000014, 1.1414648832000003, 0.8209234047999999]\n",
      "Error:  [0.08021488254618248, 1.3029420795787903, 0.5197305555884246]\n",
      "Round:  4\n",
      "Pred:  [-0.23534634051200004, 0.9721577645849601, 0.9688404880384]\n",
      "Error:  [0.1124571680947903, 0.0007751900729065042, 0.5911156960471249]\n"
     ]
    }
   ],
   "source": [
    "# Example of a multi-input multi-output gradient descent neural network:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "          # toes %win # fans   predictions:\n",
    "weights = [[0.1, 0.1, -0.3], # players hurt?\n",
    "          [0.1, 0.2, 0.0],   # did the team win?\n",
    "          [0.0, 1.3, 0.1]]   # players sad?\n",
    "\n",
    "# multiply two vectors together and then add up all the parts\n",
    "def w_sum(a, b):\n",
    "    assert (len(a) == len(b))\n",
    "    output = 0\n",
    "    for i in range(len(a)):\n",
    "        output += (a[i] * b[i])\n",
    "    return output\n",
    "\n",
    "# multiply a vector in the matrix by one outside vector, then sum the parts of the resulting vector to get one value per\n",
    "# vector in the matrix\n",
    "def vector_matrix_multiplication (vect, matrix):\n",
    "    assert(len(vect) == len(matrix))\n",
    "    output = [0, 0, 0]\n",
    "    for i in range(len(vect)):\n",
    "        output[i] = w_sum(vect, matrix[i])\n",
    "    return output\n",
    "\n",
    "# multiply the inputs by the weights to get the prediction. the weights are a set of weights for each input, each set\n",
    "# has one value corresponding to each output (matrix). the inputs are one value per input (vector).\n",
    "# we get one prediction for each output: hurt, win, sad\n",
    "def neural_network(input, weights):\n",
    "    pred = vector_matrix_multiplication(input, weights)\n",
    "    return pred\n",
    "\n",
    "# multiply input by delta to get weight_delta. multiplies each input by 3 deltas because one input goes into 3 outputs.\n",
    "# and there are 3 inputs. the inputs each contribute to each output.\n",
    "def outer_prod(vec_a, vec_b):\n",
    "    out = np.zeros([len(vec_a), len(vec_b)])\n",
    "    for i in range(len(vec_a)):\n",
    "        for j in range(len(vec_b)):\n",
    "            out[i][j] = vec_a[i] * vec_b[i]\n",
    "    return out\n",
    "\n",
    "#inputs\n",
    "toes = [8.5, 9.5, 9.9, 9.0] # current average number of toes per player\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9] # current games won (%)\n",
    "nfans = [1.2, 1.3, 0.5, 1.0] # number of fans (millions)\n",
    "\n",
    "#true value\n",
    "hurt = [0.1, 0.0, 0.0, 0.1]\n",
    "win = [1, 1, 0, 1]\n",
    "sad = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "for n in range(len(toes)):\n",
    "\n",
    "    input = [toes[n], wlrec[n], nfans[n]]\n",
    "    true = [hurt[n], win[n], sad[n]]\n",
    "\n",
    "    pred = neural_network(input, weights)\n",
    "\n",
    "    error = [0, 0, 0]\n",
    "    delta = [0, 0, 0]\n",
    "\n",
    "    # since we are only using 0th of each input and each true value, we are only getting learning for one set of inputs right now\n",
    "    for i in range(len(true)):\n",
    "        error[i] = (pred[i] - true[i]) ** 2\n",
    "        delta[i] = pred[i] - true[i]\n",
    "\n",
    "    weight_deltas = outer_prod(input, delta)\n",
    "\n",
    "    for i in range(len(weights)):\n",
    "        for j in range(len(weights[0])):\n",
    "            weights[i][j] -= alpha * weight_deltas[i][j]\n",
    "\n",
    "    # show the adjusted weight after the current round of learning\n",
    "    print(\"Round: \", n + 1)\n",
    "    print(\"Pred: \", pred)\n",
    "    print(\"Error: \", error)\n",
    "    # print(\"Weights: \", weights)\n",
    "\n",
    "# Some divergence may be happening, but we only have 4 data points. It may be happening because each time our true value\n",
    "# is different and previous examples just repeated the same true value over and over to demonstrate how the prediction \n",
    "# approaches the true value after multiple repetitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "monthly-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNISTPreprocessor notebook code provided at \n",
    "# https://github.com/iamtrask/Grokking-Deep-Learning/blob/master/MNISTPreprocessor.ipynb\n",
    "# It is essentially 4 lines long. Swapped to Python 3.8.8 to use TensorFlow.\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Load training data (set of 1000 images of handwritten numbers and their respective labels) and test data (more images and\n",
    "# labels intended to be used for seeing if the trained neural network can properly label images it has never seen before)\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "images = x_train[0:1000]\n",
    "labels = y_train[0:1000]\n",
    "\n",
    "# Images consists of 1000 arrays that are 784 long. This is because the images are 28x28, so they have 784 pixels. \n",
    "# Each pixel gets a value in the array: 1 if they are completely black and 0 if they are completely white. \n",
    "# Labels is an array that is 1000 long and each item in the array is a number between 0 and 9 (inclusive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hawaiian-barrel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]],\n",
       "\n",
       "       [[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acceptable-rebound",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0,\n",
       "       9, 1, 1, 2, 4, 3, 2, 7, 3, 8, 6, 9, 0, 5, 6, 0, 7, 6, 1, 8, 7, 9,\n",
       "       3, 9, 8, 5, 9, 3, 3, 0, 7, 4, 9, 8, 0, 9, 4, 1, 4, 4, 6, 0, 4, 5,\n",
       "       6, 1, 0, 0, 1, 7, 1, 6, 3, 0, 2, 1, 1, 7, 9, 0, 2, 6, 7, 8, 3, 9,\n",
       "       0, 4, 6, 7, 4, 6, 8, 0, 7, 8, 3, 1, 5, 7, 1, 7, 1, 1, 6, 3, 0, 2,\n",
       "       9, 3, 1, 1, 0, 4, 9, 2, 0, 0, 2, 0, 2, 7, 1, 8, 6, 4, 1, 6, 3, 4,\n",
       "       5, 9, 1, 3, 3, 8, 5, 4, 7, 7, 4, 2, 8, 5, 8, 6, 7, 3, 4, 6, 1, 9,\n",
       "       9, 6, 0, 3, 7, 2, 8, 2, 9, 4, 4, 6, 4, 9, 7, 0, 9, 2, 9, 5, 1, 5,\n",
       "       9, 1, 2, 3, 2, 3, 5, 9, 1, 7, 6, 2, 8, 2, 2, 5, 0, 7, 4, 9, 7, 8,\n",
       "       3, 2, 1, 1, 8, 3, 6, 1, 0, 3, 1, 0, 0, 1, 7, 2, 7, 3, 0, 4, 6, 5,\n",
       "       2, 6, 4, 7, 1, 8, 9, 9, 3, 0, 7, 1, 0, 2, 0, 3, 5, 4, 6, 5, 8, 6,\n",
       "       3, 7, 5, 8, 0, 9, 1, 0, 3, 1, 2, 2, 3, 3, 6, 4, 7, 5, 0, 6, 2, 7,\n",
       "       9, 8, 5, 9, 2, 1, 1, 4, 4, 5, 6, 4, 1, 2, 5, 3, 9, 3, 9, 0, 5, 9,\n",
       "       6, 5, 7, 4, 1, 3, 4, 0, 4, 8, 0, 4, 3, 6, 8, 7, 6, 0, 9, 7, 5, 7,\n",
       "       2, 1, 1, 6, 8, 9, 4, 1, 5, 2, 2, 9, 0, 3, 9, 6, 7, 2, 0, 3, 5, 4,\n",
       "       3, 6, 5, 8, 9, 5, 4, 7, 4, 2, 7, 3, 4, 8, 9, 1, 9, 2, 8, 7, 9, 1,\n",
       "       8, 7, 4, 1, 3, 1, 1, 0, 2, 3, 9, 4, 9, 2, 1, 6, 8, 4, 7, 7, 4, 4,\n",
       "       9, 2, 5, 7, 2, 4, 4, 2, 1, 9, 7, 2, 8, 7, 6, 9, 2, 2, 3, 8, 1, 6,\n",
       "       5, 1, 1, 0, 2, 6, 4, 5, 8, 3, 1, 5, 1, 9, 2, 7, 4, 4, 4, 8, 1, 5,\n",
       "       8, 9, 5, 6, 7, 9, 9, 3, 7, 0, 9, 0, 6, 6, 2, 3, 9, 0, 7, 5, 4, 8,\n",
       "       0, 9, 4, 1, 2, 8, 7, 1, 2, 6, 1, 0, 3, 0, 1, 1, 8, 2, 0, 3, 9, 4,\n",
       "       0, 5, 0, 6, 1, 7, 7, 8, 1, 9, 2, 0, 5, 1, 2, 2, 7, 3, 5, 4, 9, 7,\n",
       "       1, 8, 3, 9, 6, 0, 3, 1, 1, 2, 6, 3, 5, 7, 6, 8, 3, 9, 5, 8, 5, 7,\n",
       "       6, 1, 1, 3, 1, 7, 5, 5, 5, 2, 5, 8, 7, 0, 9, 7, 7, 5, 0, 9, 0, 0,\n",
       "       8, 9, 2, 4, 8, 1, 6, 1, 6, 5, 1, 8, 3, 4, 0, 5, 5, 8, 3, 6, 2, 3,\n",
       "       9, 2, 1, 1, 5, 2, 1, 3, 2, 8, 7, 3, 7, 2, 4, 6, 9, 7, 2, 4, 2, 8,\n",
       "       1, 1, 3, 8, 4, 0, 6, 5, 9, 3, 0, 9, 2, 4, 7, 1, 2, 9, 4, 2, 6, 1,\n",
       "       8, 9, 0, 6, 6, 7, 9, 9, 8, 0, 1, 4, 4, 6, 7, 1, 5, 7, 0, 3, 5, 8,\n",
       "       4, 7, 1, 2, 5, 9, 5, 6, 7, 5, 9, 8, 8, 3, 6, 9, 7, 0, 7, 5, 7, 1,\n",
       "       1, 0, 7, 9, 2, 3, 7, 3, 2, 4, 1, 6, 2, 7, 5, 5, 7, 4, 0, 2, 6, 3,\n",
       "       6, 4, 0, 4, 2, 6, 0, 0, 0, 0, 3, 1, 6, 2, 2, 3, 1, 4, 1, 5, 4, 6,\n",
       "       4, 7, 2, 8, 7, 9, 2, 0, 5, 1, 4, 2, 8, 3, 2, 4, 1, 5, 4, 6, 0, 7,\n",
       "       9, 8, 4, 9, 8, 0, 1, 1, 0, 2, 2, 3, 2, 4, 4, 5, 8, 6, 5, 7, 7, 8,\n",
       "       8, 9, 7, 4, 7, 3, 2, 0, 8, 6, 8, 6, 1, 6, 8, 9, 4, 0, 9, 0, 4, 1,\n",
       "       5, 4, 7, 5, 3, 7, 4, 9, 8, 5, 8, 6, 3, 8, 6, 9, 9, 1, 8, 3, 5, 8,\n",
       "       6, 5, 9, 7, 2, 5, 0, 8, 5, 1, 1, 0, 9, 1, 8, 6, 7, 0, 9, 3, 0, 8,\n",
       "       8, 9, 6, 7, 8, 4, 7, 5, 9, 2, 6, 7, 4, 5, 9, 2, 3, 1, 6, 3, 9, 2,\n",
       "       2, 5, 6, 8, 0, 7, 7, 1, 9, 8, 7, 0, 9, 9, 4, 6, 2, 8, 5, 1, 4, 1,\n",
       "       5, 5, 1, 7, 3, 6, 4, 3, 2, 5, 6, 4, 4, 0, 4, 4, 6, 7, 2, 4, 3, 3,\n",
       "       8, 0, 0, 3, 2, 2, 9, 8, 2, 3, 7, 0, 1, 1, 0, 2, 3, 3, 8, 4, 3, 5,\n",
       "       7, 6, 4, 7, 7, 8, 5, 9, 7, 0, 3, 1, 6, 2, 4, 3, 4, 4, 7, 5, 9, 6,\n",
       "       9, 0, 7, 1, 4, 2, 7, 3, 6, 7, 5, 8, 4, 5, 5, 2, 7, 1, 1, 5, 6, 8,\n",
       "       5, 8, 4, 0, 7, 9, 9, 2, 9, 7, 7, 8, 7, 4, 2, 6, 9, 1, 7, 0, 6, 4,\n",
       "       2, 5, 7, 0, 7, 1, 0, 3, 7, 6, 5, 0, 6, 1, 5, 1, 7, 8, 5, 0, 3, 4,\n",
       "       7, 7, 5, 7, 8, 6, 9, 3, 8, 6, 1, 0, 9, 7, 1, 3, 0, 5, 6, 4, 4, 2,\n",
       "       4, 4, 3, 1, 7, 7, 6, 0, 3, 6], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "competent-theology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 82575, 495450, 495450, 495450, 3468150, 3743400, 4816875, 715650, 4569150, 7018875, 6798675, 3495675, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 825750, 990900, 2587350, 4238850, 4679250, 6963825, 6963825, 6963825, 6963825, 6963825, 6193125, 4734300, 6963825, 6661050, 5367375, 1761600, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1348725, 6550950, 6963825, 6963825, 6963825, 6963825, 6963825, 6963825, 6963825, 6963825, 6908775, 2559825, 2257050, 2257050, 1541400, 1073475, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 495450, 6027975, 6963825, 6963825, 6963825, 6963825, 6963825, 5449950, 5009550, 6798675, 6633525, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2202000, 4293900, 2945175, 6963825, 6963825, 5642625, 302775, 0, 1183575, 4238850, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 385350, 27525, 4238850, 6963825, 2477250, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3825975, 6963825, 5229750, 55050, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 302775, 5229750, 6963825, 1926750, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 963375, 6633525, 6193125, 4404000, 2972700, 27525, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2229525, 6606000, 6963825, 6963825, 3275475, 688125, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1238625, 5119650, 6963825, 6963825, 4128750, 743175, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 440400, 2559825, 6936300, 6963825, 5147175, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6853725, 6963825, 6853725, 1761600, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1266150, 3578250, 5037075, 6963825, 6963825, 5697675, 55050, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1073475, 4073700, 6303225, 6963825, 6963825, 6963825, 6881250, 5009550, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 660600, 3137850, 6083025, 6963825, 6963825, 6963825, 6963825, 5532525, 2146950, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 633075, 1816650, 5862825, 6963825, 6963825, 6963825, 6963825, 5449950, 2229525, 55050, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 495450, 4706775, 6027975, 6963825, 6963825, 6963825, 6963825, 5367375, 2202000, 247725, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1513875, 4734300, 6220650, 6963825, 6963825, 6963825, 6963825, 6716100, 3660825, 302775, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3743400, 6963825, 6963825, 6963825, 5835300, 3715875, 3633300, 440400, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-87-243cfbb8d7fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#28\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#28\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m                 \u001b[0mweight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mweight_deltas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m# show the adjusted weight after the current round of learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "row = []\n",
    "for i in range(0, 28):\n",
    "    row.append([1 for _ in range(0, 28)])\n",
    "\n",
    "# made a weight array, is 28x28 and each of the 784 items is 1. starts all weights at 1. weight array is actually 10 arrays\n",
    "# of this form, one for each number 0 to 9 inclusive. deepcopy = will be editable and not change other parts of array\n",
    "weight = []\n",
    "for j in range(0, 10):\n",
    "    weight.append(deepcopy(row))\n",
    "\n",
    "# convert truth array to 784 arrays of length 10 that are filled with 0s except there is a 1 in the index position matching the\n",
    "# correct prediction.\n",
    "converted_labels = []\n",
    "for item in labels:\n",
    "    conversion = []\n",
    "    for i in range(0, 10):\n",
    "        if item == i:\n",
    "            conversion.append(1)\n",
    "        else:\n",
    "            conversion.append(0)\n",
    "    converted_labels.append(conversion)\n",
    "    \n",
    "def wsum(a, b):\n",
    "    assert (len(a) == len(b))\n",
    "    output = 0\n",
    "    for i in range(len(a)):\n",
    "        for j in range(len(a[0])):\n",
    "            output += (a[i][j] * b[i][j])\n",
    "    return output\n",
    "    \n",
    "def vm_multiplication (vect, matrix):\n",
    "    output = []\n",
    "    for i in range(len(matrix)):\n",
    "        assert(len(vect) == len(matrix[i]))\n",
    "        # w_sum just multiplies vect[n] by matrix[n] and adds this number to output, output is 1 number\n",
    "        output.append(wsum(vect, matrix[i]))\n",
    "    return output\n",
    "    \n",
    "def n_network(input, weights):\n",
    "    pred = vm_multiplication(input, weights)\n",
    "    return pred\n",
    "\n",
    "# multiply input by delta to get weight_delta (magnitude and direction of weight change to approach 0 error)\n",
    "def oprod(vec_a, vec_b):\n",
    "    out = []\n",
    "    for i in range(len(vec_a)):\n",
    "        for j in range(len(vec_a[0])):\n",
    "            out.append(vec_a[i][j] * vec_b)\n",
    "    return out\n",
    "\n",
    "for n in range(len(labels)):\n",
    "\n",
    "    input = images[n]\n",
    "    true = converted_labels[n]\n",
    "\n",
    "    # prediction should be an array of length 10 that has numbers in it. ideally, the numbers would all be 0 except the \n",
    "    # predicted value, which should be 1. hopefully something like this happens after training.\n",
    "    pred = n_network(input, weight)\n",
    "\n",
    "    # there are 10 output values, so there are 10 possible errors and 10 possible raw errors.\n",
    "    error = [0 for _ in range(0, 10)]\n",
    "    delta = [0 for _ in range(0, 10)]\n",
    "    \n",
    "    # populate the error and raw error values\n",
    "    for i in range(len(error)):\n",
    "        error[i] = (pred[i] - true[i]) ** 2\n",
    "        delta[i] = pred[i] - true[i]\n",
    "    \n",
    "    # get the \"derivative\" value aka the amount and direction we should change the weight, we must do this for EACH of the 784\n",
    "    # inputs for EACH of the 10 possible outputs. so 784 inputs will be multiplied by the 0 delta value, the 1 delta value, etc.\n",
    "    # this will produce an array 784 long for each possible output, so there are 10 arrays 784 long each in weight_deltas\n",
    "    weight_deltas = []\n",
    "    for i in range(len(delta)):\n",
    "        weight_deltas.append(oprod(input, delta[i]))\n",
    "    \n",
    "    # weight is 10 arrays that are 784 items long. subtract all 10 arrays that are 784 items long of the weight_deltas from\n",
    "    # each weight subarray\n",
    "    for i in range(len(weight)): #10\n",
    "        for j in range(len(weight[0])): #28\n",
    "            for k in range(len(weight[0][0])): #28\n",
    "                # need to fix weight_deltas generation to have a 28 array for each row instead of being 1 array of 784\n",
    "                weight[i][j][k] -= alpha * weight_deltas[i][j][k]\n",
    "\n",
    "    # show the adjusted weight after the current round of learning\n",
    "    print(\"Round: \", n + 1)\n",
    "    print(\"Pred: \", pred)\n",
    "    print(\"Error: \", error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
